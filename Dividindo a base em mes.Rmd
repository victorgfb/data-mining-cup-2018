---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    notebook_metadata_filter: jupytext_formats
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.3.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# %autosave 0
```

```{python}
import pandas as pd
import numpy as np
import datetime
from sklearn.linear_model import LogisticRegression
import re
from sklearn import preprocessing

regex = r"([0-9]{4}-[0-9]{2})-([0-9]{2})"
```

```{python}
train = pd.read_csv('train.csv', sep='|')
items = pd.read_csv('items.csv', sep='|')

items = items.fillna("None")
train = train.fillna("None")
```

```{python}
month = []
for i in train["date"]:
    month.append(re.search(regex, i).group(1))
```

```{python}
train.insert(1,"month",month)
```

```{python}
def insert_column (data,fields,fields_name):
    index = len(data.columns)-1
    for i in range(len(fields_name)):
        data.insert(index + i,fields_name[i],fields[fields_name[i]],True)
    return data
```

```{python}
items
```

```{python}
units = train.sort_values(by=['units'])['units'].reset_index()['units']
```

```{python}
units[units.index > 134000]
```

```{python}
import matplotlib.pyplot as plt 
plt.plot(units) 
   
plt.title('Units graph!') 
  
# function to show the plot 
plt.show() 
```

```{python}
train = train[train['units'] < 20]
```

```{python}
max(train['units'])
```

```{python}

```

```{python}
x = train.groupby(['pid','size','month']).tail(1).sort_values(by=['pid']).drop(['units'], axis=1)
```

```{python}
grouped = train.groupby(['pid','size','month']).sum()
```

```{python}
grouped
```

```{python}
grouped.index = x.index
```

```{python}
#x['units'] = grouped['units']
```

```{python}
x = x.sort_values(by=['pid','month'])
```

```{python}
data = pd.merge(items.drop(['stock'], axis=1), x, on=['pid','size'])
```

```{python}
data['units'] = grouped['units'].values
```

```{python}
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_X = LabelEncoder()

data['mainCategory'] = labelencoder_X.fit_transform(data['mainCategory'])
```

```{python}
#onehotencoder.fit_transform(data)
```

```{python}
# categories = pd.get_dummies(data['category'])
mainCategories = pd.get_dummies(data['mainCategory'])
# subCategories = pd.get_dummies(data['subCategory'])
# color = pd.get_dummies(data['color'])
# brand = pd.get_dummies(data['brand'])
```

```{python}
# categories.columns = ['cat-2', 'cat-7', 'cat-10', 'cat-16', 'cat-18', 'cat-24', 'cat-30', 'cat-33', 'cat-36', 'cat-37']

mainCategories.columns = ['mcat-1', 'mcat-9', 'mcat-15']

# subCategories.columns = [ 'subcat-3.0',    'subcat-4.0',    'subcat-5.0',    'subcat-6.0',    'subcat-8.0',   'subcat-11.0',   'subcat-12.0',   'subcat-13.0',   'subcat-14.0',
#          'subcat-16.0',   'subcat-17.0',   'subcat-19.0',   'subcat-20.0',   'subcat-21.0',   'subcat-22.0',   'subcat-23.0',   'subcat-25.0',   'subcat-26.0',
#          'subcat-27.0',   'subcat-28.0',   'subcat-29.0',   'subcat-31.0',   'subcat-32.0',   'subcat-34.0',   'subcat-35.0',   'subcat-38.0',   'subcat-39.0',
#          'subcat-40.0',   'subcat-41.0',   'subcat-42.0',   'subcat-43.0',   'subcat-44.0', 'subcat-None']
```

```{python}
# data = insert_column(data,categories, categories.columns)
data = insert_column(data,mainCategories, mainCategories.columns)
# data = insert_column(data,subCategories, subCategories.columns)
#data = insert_column(data, color, color.columns)
# data = insert_column(data, brand, brand.columns)
```

```{python}
data = data.drop(['category'], axis=1)
data = data.drop(['mainCategory'], axis=1)
data = data.drop(['subCategory'], axis=1)
data = data.drop(['color'], axis=1)
data = data.drop(['pid'], axis=1)
data = data.drop(['brand'], axis=1)
data = data.drop(['size'], axis=1)
data = data.drop(['releaseDate'], axis=1)
data = data.drop(['mcat-1'], axis=1)
```

```{python}
from datetime import datetime
data['target'] = data['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').day)
data = data.drop(['date'], axis=1)
```

```{python}
data_test = data[data['month'] == '2018-01']
data_test = data_test.drop(['month'], axis=1)
y_test = data_test.iloc[:,-1]
x_test = data_test.iloc[:,0:-1]

data_train = data[data['month'] != '2018-01']
data_train = data_train.drop(['month'], axis=1)
y_train = data_train.iloc[:,-1]
x_train = data_train.iloc[:,0:-1]

data = data.drop(['month'], axis=1)
y_data = data.iloc[:,-1]
x_data = data.iloc[:,0:-1]
```

```{python}
# scaler = preprocessing.StandardScaler()
# x_data = scaler.fit_transform(x_data)
```

```{python}
x_data
```

```{python}
# from sklearn.ensemble import RandomForestRegressor

# regr = RandomForestRegressor(max_depth=2, n_estima)
# regr.fit(x_train, y_train)
# regr.score(x_test, y_test)
```

```{python}
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(x_train, y_train)
regressor.score(x_test, y_test)
```

```{python}
from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MinMaxScaler

gsc = GridSearchCV( estimator=RandomForestRegressor(),param_grid={'max_depth': range(2,7),'n_estimators': (10, 50, 100, 500, 750, 1000),},cv=10, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)
grid_result = gsc.fit(x_data, y_data)
best_params = grid_result.best_params_
```

```{python}
rfr = RandomForestRegressor(max_depth=best_params["max_depth"], n_estimators=best_params["n_estimators"],random_state=False, verbose=False)
rfe.fit(x_data, y_data)
predictions = rfr.predict(x_test)
#cores = cross_val_score(rfr, x_data, y_data, cv=10, scoring='neg_mean_absolute_error')
```

```{python}
grid_result.best_params_
```

```{python}
from sklearn.metrics import r2_score
r2_score(y_data, predictions)
```

```{python}
from sklearn.svm import SVR
clf = SVR(kernel='rbf', epsilon=0.2, gamma='scale')
predictions = cross_val_predict(clf, x_data, y_data, cv=10)
```

```{python}
from sklearn.metrics import r2_score
r2_score(y_data, predictions)
```

```{python}
from sklearn.ensemble import AdaBoostRegressor
clf = AdaBoostRegressor(learning_rate=0.01, n_estimators=1000)
clf.fit(x_train, y_train)
predictions = clf.predict(x_test, y_test)
```

```{python}
from sklearn.metrics import r2_score
r2_score(y_data, predictions)
```

```{python}
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeRegressor

clf = DecisionTreeRegressor(max_depth=3)
clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
```

```{python}
from sklearn.metrics import r2_score
r2_score(y_test, predictions)
```

```{python}
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor

rng = np.random.RandomState(1)
regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=3), n_estimators=1000, random_state=rng)
regr_2.fit(x_train, y_train)
predictions = regr_2.predict(x_test)
```

```{python}
from sklearn.metrics import r2_score
r2_score(y_test, predictions)
```

```{python}

```
